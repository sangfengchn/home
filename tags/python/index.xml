<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Feng Sang | 桑峰</title>
    <link>/tags/python/</link>
    <description>Recent content in Python on Feng Sang | 桑峰</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 19 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Find clusters in a image</title>
      <link>/post/2022/01/19/blog/</link>
      <pubDate>Wed, 19 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>/post/2022/01/19/blog/</guid>
      <description>问题 我们在对神经影像数据做完统计后（例如ICA），会得到相应的mask二值文件。但是有些情况下，我们还需要进一步对mask中每一个cluster进行分析（例如计算mask中每个cluster之间的功能连接）。所以我们需要从mask文件中得到每一个cluster。由于没有想到有哪个现成的工具包可以解决上述的问题。因此，本文试图用自己的方式去解决上述的问题。
 方法 思路一 看到这个问题的时候，最朴素的想法就是用MRIcron/GL或者ITK-SNAP手动将mask中的每一个cluster标记出来。
 思路二 虽然上述手动标记的方法能解决这个问题，但是显得没那么优雅（bushi。就想换用代码解决这个问题。而且写完代码下次再碰到类似的问题，就能直接使用了（还能水一篇推送。
首先我想着先找出mask中所有非零元素的下标，然后选一个非零元素，再去判断这个元素的邻域是否是0（如果是0就意味着已经到了这个cluster的边缘）。但是在三维图像里面，要判断邻域是否到达边缘，需要写8个条件判断，这也很不优雅（主要还是找到了一个现成的轮子。
之后在找“轮子”的时候，看到了scipy包里面的一个函数可以实现上面的过程。因此通过调用它近乎完美地解决了最开始的问题（bushi。下面是相应的代码。
import nibabel as nib from scipy.ndimage import measurements import logging logging.basicConfig(level=logging.INFO) img = nib.load(&amp;#39;test-binary.nii&amp;#39;) data = img.get_fdata() labels, num_labels = measurements.label(data) logging.info(f&amp;#39;The number of cluster is {num_labels}&amp;#39;) nib.save(nib.Nifti1Image(labels, img.affine), f&amp;#39;test_cluster-mix.nii&amp;#39;) for i in range(num_labels): tmp_data = np.zeros(data.shape) tmp_data[labels == i + 1] = 1 nib.save(nib.Nifti1Image(tmp_data, img.affine), f&amp;#39;test_cluster-{i+1}.nii&amp;#39;) test-binary.nii是从Neurosynth上随便找的一个功能连接图谱，并以±0.2作为阈值得到的mask文件（Figure 1）。
 Figure 1: test-binary.nii可视化结果。  上述代码运行后，对于mask中的每一个cluster会得到一个.nii文件，同时也会得到一个混合了所有cluster的.nii文件。结果如Figure 2所示。
 Figure 2: 混合了所有cluster的结果，其中每个cluster用一个整数标记。    参考 https://neurosynth.</description>
    </item>
    
    <item>
      <title>Python for Neuroimage data</title>
      <link>/post/2021/11/20/blog/</link>
      <pubDate>Sat, 20 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021/11/20/blog/</guid>
      <description>DICOM文件 DICOM格式是医学成像设备输出的统一的文件格式，它包含数据头信息和数据信息两部分。其中头信息包含扫描设备的信息以及被试的信息等，另外还包括其他关于数据的元信息。数据部分是扫描设备采集到扫描物体的信号值。
利用Pydicom包可以使用Python操作DICOM文件，包括对DICOM文件的读写、头信息的增删改等。
安装 pip install pydicom # 或 conda install -c conda-forge pydicom  示例数据 from pydicom.data import get_testdata_file fpath = get_testdata_file(&amp;quot;CT_small.dcm&amp;quot;) fpath Out: ‘/Applications/miniconda3/lib/python3.9/site-packages/pydicom/data/test_files/CT_small.dcm’
 读入文件 from pydicom import dcmread ds = dcmread(fpath) ds 输出：
Dataset.file_meta ------------------------------- (0002, 0000) File Meta Information Group Length UL: 192 (0002, 0001) File Meta Information Version OB: b&amp;#39;\x00\x01&amp;#39; (0002, 0002) Media Storage SOP Class UID UI: CT Image Storage (0002, 0003) Media Storage SOP Instance UID UI: 1.</description>
    </item>
    
    <item>
      <title>一周小结</title>
      <link>/post/2021/09/03/blog/</link>
      <pubDate>Fri, 03 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021/09/03/blog/</guid>
      <description>Python并行处理 Python 中的concurrent包提供了对于并行运行的接口，包括进程级并行和线程级并行。下面是一个例子。
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor def func(a, b): return a*b if __name__ == &amp;#39;__main__&amp;#39;: n_core = 4 nums = 10000 b = 2 res = [0 for _ in range(nums)] with ProcessPoolExecutor(n_core) as pool: futures = {pool.submit(func, i, b): i for i in range(1, nums)} for f in futures: res[futures[f]] = f.result() res = [0 for _ in range(nums)] with ThreadPoolExecutor(n_core) as pool: futures = {pool.</description>
    </item>
    
    <item>
      <title>Python函数参数中的“*”</title>
      <link>/post/2021/06/17/blog/</link>
      <pubDate>Thu, 17 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>/post/2021/06/17/blog/</guid>
      <description>Python中，*除了可用于乘法和乘方运算外，还可以把它放在函数形式参数的前面，用来传递多个参数或进行参数的拆解。下面简单介绍后者的用法。
传递多参数 示例1 def f(*x): print(x) f(1, 2, 3, 4) 输出：(1, 2, 3, 4)
可见，虽然在定义函数f()时，只用了一个形式参数x，但是由于*的存在，再调用该函数时，即便是传递多个参数，也会把多个参数当成一个变量x（这里当作元组处理）来处理。
 示例2 def f(**x): print(x) f(a=1, b=2, c=3, d=4) 输出：{‘a’: 1, ‘b’: 2, ‘c’: 3, ‘d’: 4}
**也可以接收多个参数，但是跟*不同的是，**接收带有key的参数，并且将多个key-value形式的参数转换成为一个字典。
  拆分参数 def f(*x): print(x) # Test 1 f(1, 2) # Test 2 f((1, 2)) # Test 3 f(*(1, 2)) 三次调用的输出分别为：
Test 1: (1, 2) Test 2: ((1, 2),) Test 3: (1, 2)
Test 1的结果跟{#demo1}一样，此时的x为两个参数构成的元组。Test 2输入参数变成了一个由两个元素构成的元组，此时的x把这个元组当成一个整体作为它的第一个元素，形成了一个新的元组。Test 3在传递参数时，前面添加了*，此时函数f中的x为输入的元组本身，效果与Test 1相同。</description>
    </item>
    
  </channel>
</rss>
